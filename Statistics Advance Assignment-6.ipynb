{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83846d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32acce78",
   "metadata": {},
   "source": [
    "Normality: The data in each group must be normally distributed. This means that the data should be bell-shaped and symmetrical. If the data is not normally distributed, you can try to transform the data to make it more normally distributed. However, if the transformation does not work, you may need to use a non-parametric test.\n",
    "Homogeneity of variance: The variances of the groups must be equal. This means that the spread of the data in each group should be similar. If the variances are not equal, you can try to transform the data to make the variances more equal. However, if the transformation does not work, you may need to use a non-parametric test.\n",
    "Here are some examples of violations of the assumptions of ANOVA and how they could impact the validity of the results:\n",
    "Violation of normality: If the data is not normally distributed, the results of the ANOVA test may not be accurate. The test may be more likely to find a significant difference between the groups even when there is no real difference.\n",
    "Violation of homogeneity of variance: If the variances are not equal, the results of the ANOVA test may not be accurate. The test may be more likely to find a significant difference between the groups when the difference is actually small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ef905",
   "metadata": {},
   "source": [
    "One-way ANOVA: This is the simplest type of ANOVA and is used to compare the means of two or more groups. For example, you could use one-way ANOVA to compare the average test scores of students in different classes.\n",
    "Two-way ANOVA: This type of ANOVA is used to compare the means of two or more groups, while also taking into account the effects of another variable. For example, you could use two-way ANOVA to compare the average test scores of students in different classes, while also taking into account the effects of gender.\n",
    "Repeated Measures ANOVA: This type of ANOVA is used when you have repeated measurements or observations taken from the same subjects or units across different conditions or time points. Repeated measures ANOVA is useful for analyzing within-subject changes over time or under varying conditions. For example, in a medical study, you might measure patients' blood pressure before treatment, during treatment, and after treatment to see if there are significant changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534e402",
   "metadata": {},
   "source": [
    "artitioning of variance in ANOVA is the process of dividing the total variance in the data into two or more components. The total variance is the variation in the data that is not explained by any of the factors being analyzed. The two or more components are the variance that is explained by the factors being analyzed, and the residual variance, which is the variation that is not explained by any of the factors.\n",
    "\n",
    "The partitioning of variance is important to understand because it allows us to determine the amount of variation in the data that is explained by the factors being analyzed. This information can be used to make inferences about the relationships between the factors and the dependent variable.\n",
    "\n",
    "For example, let's say we are interested in the relationship between gender and test scores. We could use ANOVA to partition the variance in the test scores into two components: the variance that is explained by gender, and the residual variance. If the variance that is explained by gender is significant, then we can conclude that there is a relationship between gender and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd073d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 1098.9333333333334\n",
      "Explained Sum of Squares (SSE): 980.1333333333334\n",
      "Residual Sum of Squares (SSR): 118.79999999999995\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "group1 = np.array([10, 12, 14, 15, 18])\n",
    "group2 = np.array([20, 21, 24, 26, 28])\n",
    "group3 = np.array([30, 32, 33, 35, 38])\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "overall_mean = np.mean(all_data)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "group_means = [np.mean(group1), np.mean(group2), np.mean(group3)]\n",
    "sse = np.sum([len(group) * (group_mean - overall_mean)**2 for group, group_mean in zip([group1, group2, group3], group_means)])\n",
    "ssr = sst - sse\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecacd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98156c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor A: [15. 22. 30.]\n",
      "Main Effect of Factor B: [20.         22.33333333 24.66666667]\n",
      "Interaction Effect: [[-6.66666667e-01  3.55271368e-15  6.66666667e-01]\n",
      " [ 3.33333333e-01  3.55271368e-15 -3.33333333e-01]\n",
      " [ 3.33333333e-01  3.55271368e-15 -3.33333333e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = np.array([[12, 15, 18],\n",
    "                 [20, 22, 24],\n",
    "                 [28, 30, 32]])\n",
    "mean_factor_a = np.mean(data, axis=1)\n",
    "mean_factor_b = np.mean(data, axis=0)\n",
    "grand_mean = np.mean(data)\n",
    "interaction_effect = grand_mean - (mean_factor_a[:, np.newaxis] + mean_factor_b[np.newaxis, :] - data)\n",
    "print(\"Main Effect of Factor A:\", mean_factor_a)\n",
    "print(\"Main Effect of Factor B:\", mean_factor_b)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a2654",
   "metadata": {},
   "source": [
    "If you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there is a statistically significant difference between the groups. The p-value is the probability of obtaining the observed results if there is no difference between the groups. A p-value of 0.02 means that there is a 2% chance of obtaining the observed results if there is no difference between the groups.\n",
    "\n",
    "The F-statistic is a measure of the ratio of the variance between the groups to the variance within the groups. A large F-statistic indicates that the variance between the groups is larger than the variance within the groups. This suggests that there is a difference between the groups.\n",
    "\n",
    "In this case, the F-statistic is 5.23, which is considered to be a large value. The p-value is also very small, which means that the probability of obtaining the observed results if there is no difference between the groups is very small. Therefore, we can conclude that there is a statistically significant difference between the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e59cad",
   "metadata": {},
   "source": [
    "There are several ways to handle missing data in a repeated measures ANOVA. The best method to use depends on the specific situation.\n",
    "\n",
    "Listwise deletion is the simplest method to handle missing data. It involves removing all cases that have any missing data. This is the most conservative method, but it can also be the most drastic. If a lot of data is missing, it can significantly reduce the sample size and power of the study.\n",
    "\n",
    "Pairwise deletion is a less conservative method. It involves removing cases only for the variables that have missing data. This can be less drastic than listwise deletion, but it can still reduce the sample size and power of the study.\n",
    "\n",
    "Imputation is a more sophisticated method that involves replacing the missing data with estimates. There are several different imputation methods available. The best method to use depends on the specific situation.\n",
    "\n",
    "Mixed-effects models are a type of statistical model that can be used to handle missing data. These models allow for the estimation of the effects of the variables of interest, even when there is missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da12fa",
   "metadata": {},
   "source": [
    "here are some common post-hoc tests used after ANOVA, and when would you use each one:\n",
    "\n",
    "Tukey's test: This is a popular post-hoc test that is used to compare all possible pairs of means. It is relatively conservative, which means that it is less likely to find a significant difference between the means when there is actually no difference.\n",
    "Bonferroni test: This is another popular post-hoc test that is used to compare all possible pairs of means. It is more powerful than Tukey's test, which means that it is more likely to find a significant difference between the means when there is actually a difference. However, it is also more likely to find a false positive, which is a finding of a significant difference when there is actually no difference.\n",
    "Holm-Sidak test: This is a modification of the Bonferroni test that is less likely to find false positives.\n",
    "Shaffer's test: This is a modification of the Tukey test that is more powerful than Tukey's test.\n",
    "The choice of which post-hoc test to use depends on the specific situation. The factors to consider include the number of groups being compared, the level of significance desired, and the risk of making a false positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a69da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b6e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 111.11961141469351\n",
      "p-value: 9.789252682784251e-23\n",
      "Reject the null hypothesis. There are significant differences between the mean weight loss of the diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "diet_A = np.array([2.5, 3.2, 1.8, 2.9, 3.5, 2.1, 2.7, 2.0, 3.3, 2.6,\n",
    "                   2.4, 2.8, 2.2, 1.9, 2.7, 2.6, 3.0, 2.4, 3.1, 2.5,\n",
    "                   2.3, 3.2, 2.1, 2.9, 3.1])\n",
    "diet_B = np.array([1.5, 1.9, 2.0, 2.1, 1.8, 1.7, 1.6, 2.3, 1.8, 2.0,\n",
    "                   1.6, 1.9, 2.1, 2.4, 2.2, 1.8, 2.0, 1.7, 1.9, 2.3,\n",
    "                   1.5, 1.6, 1.8, 1.7, 1.9])\n",
    "diet_C = np.array([0.8, 1.2, 1.0, 1.5, 0.9, 1.1, 1.3, 1.0, 1.2, 1.4,\n",
    "                   1.5, 1.6, 1.0, 1.3, 1.1, 1.2, 1.4, 1.5, 1.3, 1.6,\n",
    "                   1.0, 1.4, 1.2, 1.1, 1.3])\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There are significant differences between the mean weight loss of the diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference between the mean weight loss of the diets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf10fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                 13.866667   2.0  0.167472  0.846780\n",
      "C(Experience)                0.533333   1.0  0.012882  0.910578\n",
      "C(Software):C(Experience)   33.866667   2.0  0.409018  0.668846\n",
      "Residual                   993.600000  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = {\n",
    "    'Software': ['A', 'B', 'C'] * 10,\n",
    "    'Experience': ['Novice'] * 15 + ['Experienced'] * 15,\n",
    "    'Time': [25, 30, 28, 35, 40, 38, 20, 24, 22, 30,\n",
    "             33, 32, 23, 25, 28, 18, 21, 20, 27, 33,\n",
    "             30, 34, 32, 36, 38, 22, 25, 28, 30, 35]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8da2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40685968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test:\n",
      "t-statistic: -10.879417464329679\n",
      "p-value: 1.5097822691714507e-18\n",
      "Reject the null hypothesis. There is a significant difference in test scores between the two groups.\n",
      "\n",
      "Tukey's HSD Post-Hoc Test Results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj lower   upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental     9.02   0.0 7.3747 10.6653   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "control_group = np.array([78, 85, 92, 75, 88, 83, 79, 91, 86, 82,\n",
    "                          79, 88, 83, 81, 76, 90, 85, 89, 80, 84,\n",
    "                          87, 92, 78, 84, 86, 81, 85, 87, 83, 80,\n",
    "                          79, 92, 85, 87, 83, 78, 81, 86, 89, 82,\n",
    "                          88, 80, 84, 76, 89, 84, 85, 81, 88, 77])\n",
    "\n",
    "experimental_group = np.array([92, 95, 96, 88, 98, 91, 86, 99, 93, 90,\n",
    "                               94, 97, 90, 85, 87, 98, 96, 91, 89, 93,\n",
    "                               96, 99, 94, 92, 91, 88, 95, 97, 92, 91,\n",
    "                               89, 97, 95, 96, 91, 92, 88, 94, 98, 90,\n",
    "                               97, 89, 93, 86, 98, 94, 95, 92, 96, 89])\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "print(\"Two-Sample T-Test:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in test scores between the two groups.\")\n",
    "data = np.concatenate([control_group, experimental_group])\n",
    "group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
    "mc = MultiComparison(data, group_labels)\n",
    "result = mc.tukeyhsd()\n",
    "print(\"\\nTukey's HSD Post-Hoc Test Results:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a7a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA:\n",
      "F-Statistic: 742.0024490383942\n",
      "p-value: 1.1902531728675174e-56\n",
      "Reject the null hypothesis. There are significant differences in sales between the stores.\n",
      "\n",
      "Tukey's HSD Post-Hoc Test Results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1  group2  meandiff p-adj   lower     upper   reject\n",
      "----------------------------------------------------------\n",
      "Store A Store B -165.8065   0.0  -184.902 -146.7109   True\n",
      "Store A Store C -308.3871   0.0 -327.4826 -289.2916   True\n",
      "Store B Store C -142.5806   0.0 -161.6762 -123.4851   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "store_a_sales = np.array([1500, 1600, 1550, 1480, 1550, 1620, 1520, 1530, 1570, 1580,\n",
    "                          1600, 1610, 1630, 1550, 1570, 1520, 1540, 1590, 1560, 1620,\n",
    "                          1580, 1630, 1590, 1560, 1540, 1550, 1610, 1600, 1520, 1530, 1570])\n",
    "\n",
    "store_b_sales = np.array([1400, 1380, 1450, 1420, 1360, 1430, 1410, 1400, 1390, 1420,\n",
    "                          1350, 1400, 1430, 1420, 1380, 1400, 1390, 1360, 1410, 1400,\n",
    "                          1420, 1390, 1380, 1400, 1410, 1420, 1430, 1400, 1380, 1410, 1390])\n",
    "\n",
    "store_c_sales = np.array([1200, 1150, 1250, 1240, 1280, 1260, 1270, 1250, 1260, 1230,\n",
    "                          1300, 1280, 1290, 1260, 1250, 1230, 1270, 1250, 1280, 1260,\n",
    "                          1280, 1270, 1290, 1240, 1260, 1300, 1270, 1280, 1290, 1230, 1240])\n",
    "data = np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "store_labels = ['Store A'] * len(store_a_sales) + ['Store B'] * len(store_b_sales) + ['Store C'] * len(store_c_sales)\n",
    "df = pd.DataFrame({'Sales': data, 'Store': store_labels})\n",
    "f_statistic, p_value = stats.f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
    "\n",
    "print(\"One-Way ANOVA:\")\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There are significant differences in sales between the stores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There are no significant differences in sales between the stores.\")\n",
    "mc = MultiComparison(df['Sales'], df['Store'])\n",
    "result = mc.tukeyhsd()\n",
    "print(\"\\nTukey's HSD Post-Hoc Test Results:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd50da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
