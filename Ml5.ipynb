{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64566772",
   "metadata": {},
   "source": [
    "Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19415028",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Min-Max scaling, also known as normalization, is a data preprocessing technique that transforms the values of numerical features into a common range, typically between 0 and 1.\n",
    "#Min-Max scaling is a simple and effective data preprocessing technique that can be used to improve the performance of machine learning algorithms. It is a good choice for normalizing numerical features that have a wide range of values.\n",
    "#Applications:\n",
    "#ML\n",
    "#NLP\n",
    "#CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa600ab",
   "metadata": {},
   "source": [
    "Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unit vector scaling is a more complex data preprocessing technique than Min-Max scaling. Min-Max scaling simply scales the values of the features so that they range from 0 to 1. Unit vector scaling, on the other hand, scales the values of the features so that they have a unit length.\n",
    "#This makes unit vector scaling more robust to noise and can improve the performance of machine learning algorithms.\n",
    "#Applications:\n",
    "#ML\n",
    "#NLP\n",
    "#Image processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65af168",
   "metadata": {},
   "source": [
    "Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e47e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pca converts higher dimension of data to lower dimension data in this variance is captured is captured\n",
    "#Applications:\n",
    "#Machine Learning\n",
    "#Deep Learning\n",
    "#Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa43c8",
   "metadata": {},
   "source": [
    "Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "043df1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pca converts higher dimension of data to lower dimension data in this variance is captured is captured\n",
    "#Feature Extraction is the process of transforming data \n",
    "#PCA can be used for feature extraction by projecting the data onto a lower-dimensional subspace that captures the most important variations in the data. This can be helpful for visualization and for reducing the computational complexity of machine learning algorithms.\n",
    "#Example Let's say we have a dataset with 100 features, and we want to reduce the dimensionality of the dataset to 5 features.\n",
    "#We can use PCA to project the data onto a 5-dimensional subspace that captures the most important variations in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4dc0b",
   "metadata": {},
   "source": [
    "Q5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293fe6d",
   "metadata": {},
   "source": [
    "step 1: Identify the features that need to be scaled. In this case, the features that need to be scaled are price, rating, and delivery time.\n",
    "Step 2: Calculate the minimum and maximum values of each feature. For example, the minimum price in the dataset might be $10, and the maximum price might be $100. The minimum rating might be 1, and the maximum rating might be 5. The minimum delivery time might be 15 minutes, and the maximum delivery time might be 60 minutes.\n",
    "Step 3: Subtract the minimum value from each value of each feature. For example, if the price of a food item is $30, then the scaled price would be 20, because 30 - 10 = 20.\n",
    "Step 4: Divide each value of each feature by the difference between the minimum and maximum values. For example, if the rating of a food item is 4, then the scaled rating would be 0.8, because 4 / (5 - 1) = 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a2d8f",
   "metadata": {},
   "source": [
    "Q6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc2434",
   "metadata": {},
   "source": [
    "tep 1: Identify the features that need to be scaled. In this case, the features that need to be scaled are company financial data and market trends.\n",
    "Step 2: Calculate the covariance matrix of the data. The covariance matrix is a square matrix that shows how each feature is correlated with each other feature.\n",
    "Step 3: Calculate the eigenvalues and eigenvectors of the covariance matrix. The eigenvalues represent the variances of the principal components, and the eigenvectors represent the directions of the principal components.\n",
    "Step 4: Select the k principal components with the largest eigenvalues. The k principal components will be the directions of the principal components that capture the most important variations in the data.\n",
    "Step 5: Project the data onto the k principal components. This will result in a k-dimensional dataset that contains the same information as the original dataset, but it will be much easier to visualize and to use for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558775b",
   "metadata": {},
   "source": [
    "Q7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45199a01",
   "metadata": {},
   "source": [
    "\n",
    "Calculate the minimum and maximum values:\n",
    "\n",
    "Minimum value (min_val): 1\n",
    "Maximum value (max_val): 20\n",
    "Apply Min-Max scaling formula:\n",
    "Min-Max scaling to the range [-1, 1] can be done using the following formula:\n",
    "\n",
    "\n",
    "scaled_value = -1 + 2 * (value - min_val) / (max_val - min_val)\n",
    "Let's calculate the scaled values for each value in the dataset:\n",
    "\n",
    "For value 1:\n",
    "\n",
    "scaled_value = -1 + 2 * (1 - 1) / (20 - 1) = -1\n",
    "For value 5:\n",
    "\n",
    "\n",
    "scaled_value = -1 + 2 * (5 - 1) / (20 - 1) = -0.5\n",
    "For value 10:\n",
    "\n",
    "\n",
    "scaled_value = -1 + 2 * (10 - 1) / (20 - 1) = 0\n",
    "For value 15:\n",
    "\n",
    "\n",
    "scaled_value = -1 + 2 * (15 - 1) / (20 - 1) = 0.5\n",
    "For value 20:\n",
    "\n",
    "\n",
    "scaled_value = -1 + 2 * (20 - 1) / (20 - 1) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c475a",
   "metadata": {},
   "source": [
    "Q8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcf35e",
   "metadata": {},
   "source": [
    "\n",
    "first four principal components is that they capture the most important variations in the data. This means that they can be used to reconstruct the original data with a high degree of accuracy. Additionally, retaining the first four principal components will reduce the dimensionality of the data without losing too much information. This can be beneficial for machine learning algorithms, as it can make the data easier to work with and can improve the performance of the algorithms.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
